{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSl3SCjXn3D19JVLaI1mjU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0j9_sloqJZVu","executionInfo":{"status":"ok","timestamp":1756261815810,"user_tz":-540,"elapsed":23938,"user":{"displayName":"アカデミックイングリッシュ","userId":"00073086376303932348"}},"outputId":"4123b77a-9e96-43e3-b7dd-818cb077d16a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# pair_extractor.py\n","import os, sys, time, threading, re, shutil\n","import pandas as pd\n","import spacy\n","\n","# ===== 環境判定 =====\n","try:\n","    import google.colab  # type: ignore\n","    IN_COLAB = True\n","except ImportError:\n","    IN_COLAB = False\n","\n","# ===== Pathの設定 =====\n","if IN_COLAB:\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\", force_remount=False)\n","\n","    WORKING_DIR_PATH = \"/content/drive/MyDrive/dep_collocation_tutorial\"\n","    CORPUS_DIR = \"NICER/nicer_plain\"\n","    INPUT_ROOT = os.path.join(WORKING_DIR_PATH, CORPUS_DIR) # /content/drive/MyDrive/dep_collocation_tutorial/NICER/nicer_plain\n","    OUTPUT_DIR = os.path.join(WORKING_DIR_PATH, \"collocation\") # /content/drive/MyDrive/dep_collocation_tutorial/collocation\n","    os.makedirs(OUTPUT_DIR, exist_ok=True)\n","    sys.path.append(WORKING_DIR_PATH) # ライブラリmylibを読み込むディレクトリを指定\n","else:\n","    # ローカル環境\n","    sys.path.append(os.path.abspath(os.path.dirname(__file__))) # 現在のスクリプトが置かれているディレクトリにあるライブラリを探す\n","\n","import mylib  # is_adj_noun / is_verb_obj / is_verb_adv / is_adv_verb / is_adv_adj\n","\n","# ===== 共通ユーティリティ =====\n","def get_all_txt_files(root_folder: str):\n","    txt_files = []\n","    for dirpath, _, filenames in os.walk(root_folder):\n","        for f in filenames:\n","            if f.lower().endswith(\".txt\"):\n","                txt_files.append(os.path.join(dirpath, f))\n","    return sorted(txt_files, key=lambda x: os.path.basename(x))\n","\n","def add_result(results, file_path, pair_type, sentence_text, i1, i2, token1, token2, span):\n","    ZERO_WIDTH = \"\".join([\"\\u200b\", \"\\u200c\", \"\\u200d\", \"\\ufeff\"])  # ZWSP/ZWNJ/ZWJ/BOM\n","    lemma1 = token1.lemma_.lower()\n","    lemma2 = token2.lemma_.lower()\n","    lemma1 = re.sub(f\"[{ZERO_WIDTH}]\", \"\", lemma1)\n","    lemma2 = re.sub(f\"[{ZERO_WIDTH}]\", \"\", lemma2)\n","    results.append({\n","        \"file\": os.path.basename(file_path),\n","        \"pair_type\": pair_type,\n","        \"sentence\": sentence_text,\n","        \"i1\": i1, \"i2\": i2,\n","        \"lemma1\": lemma1, \"lemma2\": lemma2,\n","        \"word1\": token1.text, \"word2\": token2.text,\n","        \"pos1\": token1.pos_, \"pos2\": token2.pos_,\n","        \"tag1\": token1.tag_, \"tag2\": token2.tag_,\n","        \"dep1\": token1.dep_, \"dep2\": token2.dep_,\n","        \"pair\": f\"{token1.text} - {token2.text}\",\n","        \"lemma_pair\": f\"{lemma1} - {lemma2}\",\n","        \"span\": span\n","    })\n","\n","def build_nlp():\n","    nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"textcat\"])\n","    if \"sentencizer\" not in nlp.pipe_names:\n","        nlp.add_pipe(\"sentencizer\", first=True)\n","    return nlp\n","\n","def process_files(INPUT_ROOT: str, OUTPUT_DIR: str, log_func=print):\n","    os.makedirs(OUTPUT_DIR, exist_ok=True)\n","    txt_files = get_all_txt_files(INPUT_ROOT)\n","    if not txt_files:\n","        log_func(f\"ERROR: No .txt files in {INPUT_ROOT}\")\n","        return\n","\n","    nlp_parser = build_nlp()\n","    all_results = []\n","    t0 = time.time()\n","\n","    for idx, file_path in enumerate(txt_files, 1):\n","        try:\n","            rel = os.path.relpath(file_path, INPUT_ROOT)\n","        except ValueError:\n","            rel = os.path.basename(file_path)\n","\n","        try:\n","            with open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n","                lines = f.read().splitlines()\n","        except Exception as e:\n","            log_func(f\"[WARN] Skip (read error): {rel} -> {e}\")\n","            continue\n","\n","        msg = f\"files {idx}/{len(txt_files)} : {rel}\"\n","        if log_func is print:\n","            print(\"\\r\" + msg, end=\"\", flush=True)\n","        else:\n","            log_func(msg)\n","\n","        file_results = []\n","        for line_text in lines:\n","            if not line_text.strip():\n","                continue\n","            doc_line = nlp_parser(line_text)\n","            for sent in doc_line.sents:\n","                s_start = sent.start\n","                for token in sent:\n","                    if mylib.is_adj_noun(token):\n","                        i1, i2 = token.i - s_start, token.head.i - s_start\n","                        if i1 > i2: i1, i2 = i2, i1\n","                        span = sent[i1:i2+1].text\n","                        add_result(file_results, rel, \"ADJ_NOUN\", sent.text, i1, i2, token, token.head, span)\n","                    if mylib.is_verb_obj(token):\n","                        i1, i2 = token.head.i - s_start, token.i - s_start\n","                        span = sent[i1:i2+1].text\n","                        add_result(file_results, rel, \"VERB_OBJ\", sent.text, i1, i2, token.head, token, span)\n","                    if mylib.is_verb_adv(token):\n","                        i1, i2 = token.head.i - s_start, token.i - s_start\n","                        span = sent[i1:i2+1].text\n","                        add_result(file_results, rel, \"VERB_ADV\", sent.text, i1, i2, token.head, token, span)\n","                    if mylib.is_adv_verb(token, sent):\n","                        i1, i2 = token.i - s_start, token.head.i - s_start\n","                        span = sent[i1:i2+1].text\n","                        add_result(file_results, rel, \"ADV_VERB\", sent.text, i1, i2, token, token.head, span)\n","                    if mylib.is_adv_adj(token):\n","                        i1, i2 = token.i - s_start, token.head.i - s_start\n","                        span = sent[i1:i2+1].text\n","                        add_result(file_results, rel, \"ADV_ADJ\", sent.text, i1, i2, token, token.head, span)\n","\n","        all_results.extend(file_results)\n","\n","    df_all = pd.DataFrame(all_results)\n","    if not df_all.empty:\n","        out_all = os.path.join(OUTPUT_DIR, \"pairs_all.csv\")\n","        df_all.to_csv(out_all, index=False, encoding=\"utf-8-sig\")\n","        for pt in [\"ADJ_NOUN\", \"VERB_OBJ\", \"VERB_ADV\", \"ADV_ADJ\", \"ADV_VERB\"]:\n","            sub = df_all[df_all[\"pair_type\"] == pt]\n","            if not sub.empty:\n","                freq = sub[\"lemma_pair\"].value_counts().reset_index()\n","                freq.columns = [\"lemma_pair\", \"frequency\"]\n","                freq.to_csv(os.path.join(OUTPUT_DIR, f\"frequencies_{pt}.csv\"), index=False, encoding=\"utf-8-sig\")\n","        log_func(f\"\\n✓ Results saved to: {OUTPUT_DIR}\")\n","    else:\n","        log_func(\"\\nNo dependency pairs were extracted.\")\n","    log_func(f\"✓ Total time: {time.time()-t0:.2f} sec\")\n","\n","# ===== エントリーポイント =====\n","if IN_COLAB:\n","    # =====キャッシュの設定（colab） =====\n","    print(\"[Colab] INPUT_DIR:\", INPUT_ROOT)\n","    if not os.path.isdir(INPUT_ROOT):\n","        raise FileNotFoundError(f\"Not found: {INPUT_ROOT}\")\n","    shutil.copytree(INPUT_ROOT, \"/content/text_cache\", dirs_exist_ok=True)\n","    INPUT_CACHE = \"/content/text_cache\"\n","    print(\"[Colab] Copied to :\", INPUT_CACHE)\n","    print(\"[Colab] Using cache ...\")\n","    print(\"[Colab] OUTPUT_DIR:\", OUTPUT_DIR)\n","    process_files(INPUT_CACHE, OUTPUT_DIR, log_func=print)\n","\n","else:\n","    # --- Local GUI: 入力/出力をGUIで選択して開始 ---\n","    import tkinter as tk\n","    from tkinter import filedialog, messagebox, ttk\n","\n","    class App(tk.Tk):\n","        def __init__(self):\n","            super().__init__()\n","            self.title(\"PairExtractor\")\n","            self.geometry(\"720x520\")\n","            self.input_dir = tk.StringVar()\n","            self.output_dir = tk.StringVar()\n","            # PNGファイルを指定\n","            #icon = tk.PhotoImage(file=\"icon.png\")\n","            #self.iconphoto(True, icon)\n","\n","            pad = {\"padx\": 10, \"pady\": 8}\n","\n","            frm_in = ttk.LabelFrame(self, text=\"Input\")\n","            frm_in.pack(fill=\"x\", **pad)\n","            ttk.Button(frm_in, text=\"Input folder\", command=self.select_input).pack(anchor=\"w\", padx=10, pady=(10,4))\n","            ttk.Entry(frm_in, textvariable=self.input_dir, state=\"readonly\").pack(fill=\"x\", padx=10, pady=(0,10))\n","\n","            frm_out = ttk.LabelFrame(self, text=\"Output\")\n","            frm_out.pack(fill=\"x\", **pad)\n","            ttk.Button(frm_out, text=\"Output folder\", command=self.select_output).pack(anchor=\"w\", padx=10, pady=(10,4))\n","            ttk.Entry(frm_out, textvariable=self.output_dir, state=\"readonly\").pack(fill=\"x\", padx=10, pady=(0,10))\n","\n","            frm_start = ttk.Frame(self); frm_start.pack(fill=\"x\", **pad)\n","            self.btn_start = ttk.Button(frm_start, text=\"Extract start\", command=self.on_start, state=\"disabled\")\n","            self.btn_start.pack(side=\"left\")\n","            self.lbl_status = ttk.Label(frm_start, text=\"Select input/output folders.\")\n","            self.lbl_status.pack(side=\"left\", padx=10)\n","\n","            frm_log = ttk.LabelFrame(self, text=\"Log\")\n","            frm_log.pack(fill=\"both\", expand=True, padx=10, pady=10)\n","            cnt = ttk.Frame(frm_log)\n","            cnt.pack(fill=\"both\", expand=True)\n","            self.txt_log = tk.Text(cnt, height=14, wrap=\"none\")\n","            self.txt_log.pack(side=\"left\", fill=\"both\", expand=True)\n","            self.scroll_y = ttk.Scrollbar(cnt, orient=\"vertical\", command=self.txt_log.yview)\n","            self.scroll_y.pack(side=\"right\", fill=\"y\")\n","            self.txt_log.configure(yscrollcommand=self.scroll_y.set)\n","\n","        def select_input(self):\n","            p = filedialog.askdirectory(title=\"Select input folder (e.g., JPN_text)\")\n","            if p:\n","                self.input_dir.set(p); self.update_state()\n","\n","        def select_output(self):\n","            p = filedialog.askdirectory(title=\"Select output folder (empty or existing)\")\n","            if p:\n","                self.output_dir.set(p); self.update_state()\n","\n","        def update_state(self):\n","            self.btn_start.config(state=(tk.NORMAL if self.input_dir.get() and self.output_dir.get() else tk.DISABLED))\n","\n","        def log(self, msg):\n","            self.txt_log.insert(\"end\", msg + \"\\n\"); self.txt_log.see(\"end\"); self.update_idletasks()\n","\n","        def on_start(self):\n","            in_p, out_p = self.input_dir.get().strip(), self.output_dir.get().strip()\n","            if not in_p or not out_p:\n","                messagebox.showwarning(\"Warning\", \"Both input and output folders must be selected.\"); return\n","            self.btn_start.config(state=\"disabled\"); self.lbl_status.config(text=\"Running...\")\n","            threading.Thread(target=self._run, args=(in_p, out_p), daemon=True).start()\n","\n","        def _run(self, in_p, out_p):\n","            try:\n","                process_files(in_p, out_p, log_func=self.log)\n","                self.lbl_status.config(text=\"Done.\")\n","            except Exception as e:\n","                self.log(f\"[ERROR] {e}\"); messagebox.showerror(\"Error\", str(e)); self.lbl_status.config(text=\"Error.\")\n","            finally:\n","                self.btn_start.config(state=\"normal\")\n","\n","    if __name__ == \"__main__\":\n","        App().mainloop()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zTilIlfXJxsn","outputId":"bf2a2a72-dcf4-4fba-afb3-e53b0e5a29d4","executionInfo":{"status":"ok","timestamp":1756262468518,"user_tz":-540,"elapsed":54783,"user":{"displayName":"アカデミックイングリッシュ","userId":"00073086376303932348"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[Colab] INPUT_DIR: /content/drive/MyDrive/dep_collocation_tutorial/NICER/nicer_plain\n","[Colab] Copied to : /content/text_cache\n","[Colab] Using cache ...\n","[Colab] OUTPUT_DIR: /content/drive/MyDrive/dep_collocation_tutorial/collocation\n","files 381/381 : JPN881_plain.txt\n","✓ Results saved to: /content/drive/MyDrive/dep_collocation_tutorial/collocation\n","✓ Total time: 49.09 sec\n"]}]}]}